# -*- coding: utf-8 -*-
"""11_010_Кулакова_3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zd31iiTtpzD73_PFc46cWaTatr_iwmPm
"""

from google.colab import drive
drive.mount('/content/drive')

import gc

"""# Цифровое представление основных типов данных

## 1. Графические данные
"""

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
#from matplotlib.image import imread
from skimage.io import imread
# %matplotlib inline

url = 'https://www.osp.ru/FileStorage/DOCUMENTS_ILLUSTRATIONS/13234504/original.jpg'
orig_img = imread(url)

value = int(round((orig_img.shape[0] * orig_img.shape[1] / 10)**0.5))
first = int(round((orig_img.shape[0] - value) / 2))
second = int(round((orig_img.shape[1] - value) / 2))
for i in range(first, first + value + 1):
  for j in range(second, second + value + 1):
      orig_img[i, j, 0] = 255
      orig_img[i, j, 1] = 255
      orig_img[i, j, 2] = 255
plt.imshow(orig_img)

"""## ДЗ №1

1. Поместить в центр рисунка белый квадрат, занимающий 10% площади рисунка.

## 2. Видео и звук

### Видео поток

```python
pip install opencv-python
conda install -c conda-forge opencv
```
"""

import cv2
from datetime import datetime
from google.colab.patches import cv2_imshow
import random

capture = cv2.VideoCapture(0 + cv2.CAP_DSHOW)
size = 50

while True:
    rtrn, image = capture.read()
    if image is None:
        from skimage import io
        image = io.imread('https://www.osp.ru/FileStorage/DOCUMENTS_ILLUSTRATIONS/13234504/original.jpg');
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    now = datetime.now()
    date_time = now.strftime("%d/%m/%Y, %H:%M:%S")
    pw = random.randint(0, image.shape[0] - size)
    ph = random.randint(0, image.shape[1] - size)
    for i in range(pw, pw + size):
      for j in range(ph, ph + size):
        image[i, j] = (255, 255, 255)
    cv2.putText(image, date_time, (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1., (0,255,255), 2)
    # cv2.imshow("OpenCV", image)
    cv2_imshow(image)


    if cv2.waitKey(1) & 0xFF == ord('q'): # == 27:
        break

capture.release()
cv2.destroyAllWindows()

"""отдельно создан скрипт video_stream_1.py, если будет некорректно работать в ноутбуке"""

import cv2
from datetime import datetime
from google.colab.patches import cv2_imshow

url = 'https://example-files.online-convert.com/video/mp4/example_small.mp4'
capture = cv2.VideoCapture(url)

while True:
    rtrn, image = capture.read()
    if image is None:
        break

    now = datetime.now()
    date_time = now.strftime("%d/%m/%Y, %H:%M:%S")
    cv2.putText(image, date_time, (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1., (0,255,255), 2)
    # cv2.imshow("OpenCV", image)
    cv2_imshow(image)

    if cv2.waitKey(1) & 0xFF == ord('q'): # == 27:
        break

capture.release()
cv2.destroyAllWindows()

"""отдельно создан скрипт video_stream_2.py, если будет некорректно работать в ноутбуке

## ДЗ №2

1. Поместить в случайном месте каждого кадра видеопотока белый кварат со стороной 50 px.

### Аудио данные

```python
pip install SpeechRecognition
pip install PyAudio
pip install librosa
```
"""

!pip install SpeechRecognition
!pip install ffmpeg-python
!apt install libasound2-dev portaudio19-dev libportaudio2 libportaudiocpp0 ffmpeg
!pip install PyAudio

# !git clone https://people.csail.mit.edu/hubert/git/pyaudio.git - может не сработать

# !pip install PyAudio - может не сработать

import pyaudio
import wave
from IPython.display import HTML, Audio
from google.colab.output import eval_js
from base64 import b64decode
import numpy as np
from scipy.io.wavfile import read as wav_read
import io
import ffmpeg

# https://habr.com/ru/post/577806/

# import pyaudio
# import wave
# from IPython.display import HTML, Audio
# from google.colab.output import eval_js
# from base64 import b64decode
# import numpy as np
# from scipy.io.wavfile import read as wav_read
# import io
# import ffmpeg

# CHUNK = 1024 # определяет форму ауди сигнала
# FRT = pyaudio.paInt16 # шестнадцатибитный формат задает значение амплитуды
# CHAN = 1 # канал записи звука
# RT = 44100 # частота
# REC_SEC = 5 #длина записи
# OUTPUT = "output.wav"
# # OUTPUT = '/content/drive/MyDrive/KFU/data/Levitan-Stalingrad-Ct.wav'

# p = pyaudio.PyAudio()

# stream = p.open(format=FRT,channels=CHAN,rate=RT,input=True,frames_per_buffer=CHUNK) # открываем поток для записи
# print("rec")
# frames = [] # формируем выборку данных фреймов
# for i in range(0, int(RT / CHUNK * REC_SEC)):
#     data = stream.read(CHUNK)
#     frames.append(data)
# print("done")

# stream.stop_stream() # останавливаем и закрываем поток
# stream.close()
# p.terminate()

# w = wave.open(OUTPUT, 'wb')
# w.setnchannels(CHAN)
# w.setsampwidth(p.get_sample_size(FRT))
# w.setframerate(RT)
# w.writeframes(b''.join(frames))
# w.close()

"""У кода выше может быть проблема с доступом к устройству - микрофон. Нужно разбираться либо с колабом https://ricardodeazambuja.com/deep_learning/2019/03/09/audio_and_video_google_colab/

Либо в юпитере ноутбуке. Некотjрые библиотеки могут некорректно установиться или не установиться.

Если не получится с доступом - можно воспользоваться любым аудио-файлом `.wav`

https://colab.research.google.com/gist/ricardodeazambuja/03ac98c31e87caf284f7b06286ebf7fd/microphone-to-numpy-array-from-your-browser-in-colab.ipynb
"""

"""
To write this piece of code I took inspiration/code from a lot of places.
It was late night, so I'm not sure how much I created or just copied o.O
Here are some of the possible references:
https://blog.addpipe.com/recording-audio-in-the-browser-using-pure-html5-and-minimal-javascript/
https://stackoverflow.com/a/18650249
https://hacks.mozilla.org/2014/06/easy-audio-capture-with-the-mediarecorder-api/
https://air.ghost.io/recording-to-an-audio-file-using-html5-and-js/
https://stackoverflow.com/a/49019356
"""
from IPython.display import HTML, Audio
from google.colab.output import eval_js
from base64 import b64decode
import numpy as np
from scipy.io.wavfile import read as wav_read
import io
import ffmpeg

AUDIO_HTML = """
<script>
var my_div = document.createElement("DIV");
var my_p = document.createElement("P");
var my_btn = document.createElement("BUTTON");
var t = document.createTextNode("Press to start recording");

my_btn.appendChild(t);
//my_p.appendChild(my_btn);
my_div.appendChild(my_btn);
document.body.appendChild(my_div);

var base64data = 0;
var reader;
var recorder, gumStream;
var recordButton = my_btn;

var handleSuccess = function(stream) {
  gumStream = stream;
  var options = {
    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k
    mimeType : 'audio/webm;codecs=opus'
    //mimeType : 'audio/webm;codecs=pcm'
  };
  //recorder = new MediaRecorder(stream, options);
  recorder = new MediaRecorder(stream);
  recorder.ondataavailable = function(e) {
    var url = URL.createObjectURL(e.data);
    var preview = document.createElement('audio');
    preview.controls = true;
    preview.src = url;
    document.body.appendChild(preview);

    reader = new FileReader();
    reader.readAsDataURL(e.data);
    reader.onloadend = function() {
      base64data = reader.result;
      //console.log("Inside FileReader:" + base64data);
    }
  };
  recorder.start();
  };

recordButton.innerText = "Recording... press to stop";

navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);


function toggleRecording() {
  if (recorder && recorder.state == "recording") {
      recorder.stop();
      gumStream.getAudioTracks()[0].stop();
      recordButton.innerText = "Saving the recording... pls wait!"
  }
}

// https://stackoverflow.com/a/951057
function sleep(ms) {
  return new Promise(resolve => setTimeout(resolve, ms));
}

var data = new Promise(resolve=>{
//recordButton.addEventListener("click", toggleRecording);
recordButton.onclick = ()=>{
toggleRecording()

sleep(2000).then(() => {
  // wait 2000ms for the data to be available...
  // ideally this should use something like await...
  //console.log("Inside data:" + base64data)
  resolve(base64data.toString())

});

}
});

</script>
"""

def get_audio():
    display(HTML(AUDIO_HTML))
    data = eval_js("data")
    binary = b64decode(data.split(',')[1])

    # Конвертирование аудио в формат WAV
    process = (ffmpeg
               .input('pipe:0')
               .output('pipe:1', format='wav')
               .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True, quiet=True, overwrite_output=True)
               )
    output, err = process.communicate(input=binary)

    riff_chunk_size = len(output) - 8
    # Break up the chunk size into four bytes, held in b.
    q = riff_chunk_size
    b = []
    for i in range(4):
        q, r = divmod(q, 256)
        b.append(r)

    # Replace bytes 4:8 in proc.stdout with the actual size of the RIFF chunk.
    riff = output[:4] + bytes(b) + output[8:]

    sr, audio = wav_read(io.BytesIO(riff))

    # Сохранение аудио в файле WAV
    with open("recorded_audio.wav", "wb") as wav_file:
        wav_file.write(riff)

    return audio, sr

audio, sr = get_audio()

gc.collect()

# OUTPUT = '/content/drive/MyDrive/KFU/data/Levitan-Stalingrad-Ct.wav'
OUTPUT = '/content/recorded_audio.wav'

# OUTPUT = "output.wav"

import speech_recognition as speech_r
r = speech_r.Recognizer()
harvard = speech_r.AudioFile(OUTPUT)
with harvard as source:
    audio = r.record(source)

print(r.recognize_google(audio, language="ru-RU"))

gc.collect()

import librosa
import librosa.display
import matplotlib.pyplot as plt

# OUTPUT = "output.wav"
# OUTPUT = '/content/drive/MyDrive/KFU/data/Levitan-Stalingrad-Ct.wav'
OUTPUT = '/content/drive/MyDrive/KFU/data/T08-violin.wav'

# data - массив данных временного ряда аудио, sample_rate - частота дискретизации временного ряда
data, sample_rate = librosa.load(OUTPUT, sr=None)

import matplotlib.pyplot as plt
import librosa.display

plt.figure(figsize=(14, 5))
librosa.display.waveshow(data, sr=sample_rate) #Выводим сигнал на экран

import IPython.display as ipd
ipd.Audio(OUTPUT)

print(type(data), type(sample_rate))
print(data.shape, sample_rate)
print(data.shape[0]/sample_rate)

plt.figure(figsize=(14, 5))
librosa.display.waveshow(data[:10000], sr=sample_rate) #первые 10000 значений амплитуды сигнала
plt.show()

plt.figure(figsize=(14, 5))
plt.plot(data[:1000]) #первые 1000 значений амплитуды сигнала

#Вычисляем спектр сигнала
X = librosa.stft(data)
#Переводим формат спектра в амплитуду
# Меняем шкалу на децибелы(для удобного отображения)
Xdb = librosa.amplitude_to_db(abs(X))

#Выводим спектрограмму на экран
plt.figure(figsize=(14, 5))#задаем размер
librosa.display.specshow(Xdb, sr=sample_rate, x_axis='time', y_axis='hz') #Отобразим спектрограммы
plt.colorbar()#выведем цветовую шкалу
plt.show()#выводим график

#Меняем формат оси y на логарифм
plt.figure(figsize=(14, 5))#задаем размер
librosa.display.specshow(Xdb, sr=sample_rate, x_axis='time', y_axis='log')#Отобразим спектрограммы
plt.colorbar()#выведем цветовую шкалу
plt.show()#выводим график

"""##### извлечение признаков"""

n0 = 0 #Задаём начальную точку отображения
n1 = 40 #Задаём конечную точку отображения
f = [0, 40]
#Отобраджаем сигнал
plt.figure(figsize=(14, 5))  # задаем размер графика
plt.plot(data[n0:n1]) #От начальной до конечной точки
plt.hlines(0, 0, 40)
plt.grid(which='minor',
        color = 'gray',
        linestyle = ':')
plt.show() #выводим график

# Раcчитываем пересечения нуля
zero_crossings = librosa.zero_crossings(data[0:40], pad=False)
# Отображаем результаты
print(sum(zero_crossings)) # Суммарное количество пересечений
print(zero_crossings)      # Наличие пересечения в каждой точке

from sklearn import preprocessing #Для нормирования

#Вычисляем спектральный центроид
spectral_centroids = librosa.feature.spectral_centroid(y=data, sr=sample_rate)[0]
print(data.shape)

#Вычисляем время для визуализации
frames = range(len(spectral_centroids))
t = librosa.frames_to_time(frames)

#Нормализуем спектральный центроид к отрезку 0-1
def normalize(x, axis=0):
  return preprocessing.minmax_scale(x, axis=axis)

#Строим график сигнала и спектрального центроида
plt.figure(figsize=(10,10))
librosa.display.waveshow(data, sr=sample_rate, alpha=0.4) #Построим амплитуду сигнала
plt.plot(t, normalize(spectral_centroids), color='r') #Построим график нормализованого спектрального центроида
plt.show()#выводим графики

print(spectral_centroids.shape)

# Вычисляем и отображаем спектральный спад частоты
spectral_rolloff = librosa.feature.spectral_rolloff(y=data, sr=sample_rate, roll_percent=0.90)[0]
plt.figure(figsize=(10,10))
librosa.display.waveshow(data, sr=sample_rate, alpha=0.4) # Построим амплитуду сигнала
plt.plot(t, normalize(spectral_rolloff), color='r') # Построим график нормализованого спектрального спада частоты
plt.show() # Выводим график

#Вычисляем и отображаем Мел-частотные кепстральные коэффициенты
mfccs = librosa.feature.mfcc(y=data, sr=sample_rate)
print(mfccs.shape)
librosa.display.specshow(mfccs, sr=sample_rate, x_axis='time') #Отобразим спектрограммы
plt.show()#выведим график

#Нормируем Мел коэффициенты
mfccs = preprocessing.scale(mfccs, axis=1)
#Выводим среднее значение
print(mfccs.mean(axis=1))
#Выводим среднеквадратичное отклонение
print(mfccs.var(axis=1))
#Отображаем нормированные коэффициенты
librosa.display.specshow(mfccs, sr=sample_rate, x_axis='time') #Отобразим спектрограммы
plt.show()#выведим график

hop_length = 512 #Задаём размер отрезка сигнала, по которому расcчитывается частоты цветности
#Расчитываем и отображаем частоту цветности
chromagram = librosa.feature.chroma_stft(y=data, sr=sample_rate, hop_length=hop_length)
print(chromagram.shape)
plt.figure(figsize=(15, 5))#зададим размер графика
librosa.display.specshow(chromagram, x_axis='time', y_axis='chroma', hop_length=hop_length, cmap='coolwarm') #Отобразим спектрограммы
plt.show()#выведим график

"""## ESC-50: Dataset for Environmental Sound Classification

https://dagshub.com/kinkusuma/esc50-dataset
"""

import numpy as np
import librosa
import soundfile as sf
import io
from six.moves.urllib.request import urlopen

audio_data = 'https://dagshub.com/kinkusuma/esc50-dataset/raw/3b812aa828f357df417069600a096c31816c5ef3/dataset/1-17970-A-4.wav'

# data - массив данных временного ряда аудио, sample_rate - частота дискретизации временного ряда
data, sample_rate = sf.read(io.BytesIO(urlopen(audio_data).read()))
#data, sample_rate = librosa.load(audio_data, sr=None)

import IPython.display as ipd
ipd.Audio(audio_data)

import matplotlib.pyplot as plt
import librosa.display

plt.figure(figsize=(14, 5))
librosa.display.waveshow(data, sr=sample_rate) # data - массив данных временного ряда аудио, sr - частота дискретизации временного ряда

left = 0
right = 220000

print(data.shape)
print(data[left:right].max() - data[left:right].min())

X = librosa.stft(data)
Xdb = librosa.amplitude_to_db(abs(X))

plt.figure(figsize=(14, 5))
librosa.display.specshow(Xdb, sr=sample_rate, x_axis='time', y_axis='hz')
plt.colorbar()

three_seconds = sample_rate * 3
data_ = data[:three_seconds]

timesteps = np.arange(len(data_)) / sample_rate  # in seconds

fig, ax = plt.subplots(2, figsize=(12, 5))
fig.subplots_adjust(hspace=0.5)

# plot the entire clip
ax[0].plot(timesteps, data_)
ax[0].set_xlabel('Time (s)')
ax[0].set_ylabel('Amplitude')
ax[0].set_title('Raw Audio: {} ({} samples)'.format('wav', len(data)))


n_fft = 1024*20 # frame length
start = 40000 # start at a part of the sound thats not silence..
x = data_[start:start+n_fft]

# mark location of frame in the entire signal
ax[0].axvline(start/sample_rate, c='r')
ax[0].axvline((start+n_fft)/sample_rate, c='r')

# plot N samples
ax[1].plot(x)
ax[1].set_xlabel('Samples')
ax[1].set_ylabel('Amplitude')
ax[1].set_title('Raw Audio: {} ({} samples)'.format('original wav', len(x)));

hop_length = 512
stft = librosa.stft(x, n_fft=n_fft, hop_length=hop_length)
stft_magnitude, stft_phase = librosa.magphase(stft)
stft_magnitude_db = librosa.amplitude_to_db(stft_magnitude, ref=np.max)

plt.figure(figsize=(12, 6))
librosa.display.specshow(stft_magnitude_db, x_axis='time', y_axis='linear',
                         sr=sample_rate, hop_length=hop_length)

title = 'n_fft={},  hop_length={},  time_steps={},  fft_bins={}  (2D resulting shape: {})'
plt.title(title.format(n_fft, hop_length,
                       stft_magnitude_db.shape[1],
                       stft_magnitude_db.shape[0],
                       stft_magnitude_db.shape));

"""## ДЗ №3

1. Найти в обучающем наборе esc50-dataset WAV файл с лаем собаки;
2. визуально по графику амплитуды звуковой волны найти участок файла непосредственно содержащий звук лая;
3. построить спектрограмму для найденного участка;
4. подумать (и реализовать), как с помощиью цифрового представления звука можно автоматизировать удаление части файла, не содержащего полезной информации.
"""

import librosa
import numpy as np
import soundfile as sf
import io
from six.moves.urllib.request import urlopen
import librosa.display
import matplotlib.pyplot as plt
audio_data = 'https://dagshub.com/kinkusuma/esc50-dataset/raw/3b812aa828f357df417069600a096c31816c5ef3/dataset/1-18074-A-6.wav'
data, sample_rate = sf.read(io.BytesIO(urlopen(audio_data).read()))
plt.figure(figsize=(14, 5))
librosa.display.waveshow(data, sr=sample_rate)

three_seconds = sample_rate * 3
data_ = data[:three_seconds]

timesteps = np.arange(len(data_)) / sample_rate

fig, ax = plt.subplots(1, figsize=(12, 5))

# plot the entire clip
ax.plot(timesteps, data_)
ax.set_xlabel('Time (s)')
ax.set_ylabel('Amplitude')
ax.set_title('Raw Audio: {} ({} samples)'.format('wav', len(data)))

n_fft = 1024*10
start = 28000
x = data_[start:start+n_fft]

ax.axvline(start/sample_rate, c='r')
ax.axvline((start+n_fft)/sample_rate, c='r')

"""## 3. Таблицы и временные ряды"""

import pandas as pd

url = 'https://raw.githubusercontent.com/pcsanwald/kaggle-titanic/master/train.csv'
df = pd.read_csv(url, on_bad_lines='skip', delimiter=',')
df.head()

import numpy as np
import matplotlib.pyplot as plt
import requests

series = np.empty((0,2), dtype='f')

url = 'https://raw.githubusercontent.com/sjackman/bc/master/data/astro/sunspot.txt'
response = requests.get(url)
data = response.text
data = data.split("\n") # then split it into lines

#print(data)
for i,line in enumerate(data):
    if i<3: continue
    words = line.split()
    if len(words) < 6: continue
    #print([[i-3], float(words[-1])])
    series = np.append(series, [[i-3, float(words[-1])]], axis=0)

print(series)
X = series[:,0]
y = series[:,1]

plt.figure(figsize=(20,10))
plt.plot(X,y)
plt.scatter(X,y)
plt.xlim(200,1500)
plt.show()

def moving_average(series, windowsize):
    result = [series[windowsize-1]]
    for t in range(windowsize,len(series)):
        result.append(sum(series[t-n] for n in range(windowsize)) / (windowsize))
    return result

k = 50
y_ma = moving_average(y,k)

plt.figure(figsize=(20,10))
plt.plot(X,y)
plt.scatter(X,y)
plt.plot(X[k-1:], y_ma, c='r', linewidth=3)
plt.xlim(200,1500)
plt.show()

"""### ~~Местоположение автобусов города Казани~~

http://data.kzn.ru/dinamic_datasets/bus - Это ссылка больше не работает
"""

# import urllib.request
# import json

# url = "http://data.kzn.ru:8082/api/v0/dynamic_datasets/bus.json"
# req = urllib.request.Request(url)
# r = urllib.request.urlopen(req).read()
# data = json.loads(r.decode('utf-8'))
# print(data[0])

# url = "http://data.kzn.ru:8082/api/v0/dynamic_datasets/bus/2663.json"
# req = urllib.request.Request(url)
# r = urllib.request.urlopen(req).read()
# data = json.loads(r.decode('utf-8'))
# print(data)

# import numpy as np
# import threading

# location = []

# run_num = 0
# def run_check():
#     global run_num, location
#     if run_num < 3:
#         threading.Timer(100.0, run_check).start()
#     url = "http://data.kzn.ru:8082/api/v0/dynamic_datasets/bus/2663.json"
#     req = urllib.request.Request(url)
#     r = urllib.request.urlopen(req).read()
#     data = json.loads(r.decode('utf-8'))
#     print(data['data']['Latitude'], data['data']['Longitude'])
#     location.append([float(data['data']['Latitude']), float(data['data']['Longitude'])])
#     run_num += 1

# run_check()

# location = [[55.841187, 49.082653], [55.842224, 49.084283]]
# print(location)

"""### Работа с геоданными в Python и Jupyter

https://proglib.io/p/rabota-s-geodannymi-v-python-i-jupyter-2021-03-22

```python
pip install ipyleaflet
```
"""

!pip install ipyleaflet

# from ipyleaflet import AntPath, WidgetControl
# from ipyleaflet import Map, Marker, Popup
# from ipywidgets import IntSlider, jslink
# from ipywidgets import HTML

# m = Map(center=tuple(location[0]), zoom=13)

# bus_path = AntPath(
#     locations=location,
#     dash_array=[1, 10],
#     delay=1000,
#     color='#9500ff',
#     pulse_color='#9500ff'
# )

# m.add_layer(bus_path)

# start_marker = Marker(location=tuple(location[0]))
# m.add_layer(start_marker)

# finish_marker = Marker(location=tuple(location[-1]))
# m.add_layer(finish_marker)

# start = HTML()
# finish = HTML()
# start.value = "Старт"
# finish.value = "Финиш!"
# start_marker.popup = start
# finish_marker.popup = finish

# zoom_slider = IntSlider(description='Масштаб:', min=11, max=15, value=15)
# jslink((zoom_slider, 'value'), (m, 'zoom'))
# widget_control1 = WidgetControl(widget=zoom_slider, position='topright')
# m.add_control(widget_control1)

# m

# Простой пример
import folium

# Создаем объект карты
m = folium.Map(location=[51.5074, -0.1278], zoom_start=10)  # Начальные координаты и масштаб

# Добавляем маркер на карту
folium.Marker([51.5074, -0.1278], tooltip='Лондон').add_to(m)

# Добавляем круг на карту
folium.Circle(
    location=[51.5074, -0.1278],
    radius=5000,  # радиус в метрах
    color='blue',
    fill=True,
    fill_color='blue',
    fill_opacity=0.2,
    tooltip='Окрестности Лондона',
).add_to(m)

# Отображаем карту
m.save('dynamic_map.html')  # Сохраняем карту в HTML файл

"""#### Карта точек WiFi"""

!pip install ipyleaflet
!pip install ipywidgets

import pandas as pd
from ipywidgets import HTML
from ipyleaflet import Map, Marker, Popup
from ipyleaflet import AwesomeIcon
from ipyleaflet import AntPath, WidgetControl
from ipywidgets import IntSlider, jslink
from ipyleaflet import Icon

file_name = 'https://raw.githubusercontent.com/tttdddnet/Python-Jupyter-Geo/main/data-9776-2020-12-21.csv'
df = pd.read_csv(file_name, sep=';', encoding='cp1251')
df.head()

wifi_points = []
i = 0
while i < len(df.index):
    wifi_points.append({'index': i, 'Coordinates': [df['Latitude_WGS84'][i], df['Longitude_WGS84'][i]], 'Location': df['Location'][i], 'NumberOfAccessPoints': df['NumberOfAccessPoints'][i]})
    i += 1

marker_coordinates = [wifi['Coordinates'] for wifi in wifi_points]
marker_coordinates = [[float(x) for x in y] for y in marker_coordinates]

m = Map(center=(55.753215, 37.622504), zoom=11)

markers = [Marker(location=(marker_coordinates[i])) for i in range(len(marker_coordinates))]

info_box_template = """
<dl>
<dt>Адрес:</dt><dd>{Location}</dd>
<dt>Количество точек доступа:</dt><dd>{NumberOfAccessPoints}</dd>
</dl>
"""

locations_info  = [info_box_template.format(**point) for point in wifi_points]

for i in range(len(markers)):
    markers[i].popup = HTML(locations_info[i])
    m.add_layer(markers[i])

# m

m.save('wifi_map.html')  # Сохраняем карту в HTML файл

"""#### марафон"""

m = Map(center=(55.718148, 37.555493), zoom=13)

marathon_path = AntPath(
    locations=[
        [55.717435, 37.561014], [55.712517, 37.569324], [55.712412, 37.569479],
        [55.711333, 37.561858], [55.711344, 37.558516], [55.712049, 37.553513],
        [55.713216, 37.550191], [55.71523, 37.54681], [55.717366, 37.544289],
        [55.719874, 37.542966], [55.721958, 37.542939], [55.723928, 37.543701],
        [55.725656, 37.545167], [55.7267, 37.546673], [55.727594, 37.54923],
        [55.727481, 37.549349], [55.727053, 37.547923], [55.726619, 37.546807],
        [55.724107, 37.549236], [55.723902, 37.549511], [55.720267, 37.5558]
    ],
    dash_array=[1, 10],
    delay=1000,
    color='#9500ff',
    pulse_color='#9500ff'
)

m.add_layer(marathon_path)

start_marker = Marker(location=(55.717435, 37.561014))
m.add_layer(start_marker)

finish_marker = Marker(location=(55.720267, 37.5558))
m.add_layer(finish_marker)

start = HTML()
finish = HTML()
start.value = "Старт"
finish.value = "Финиш!"
start_marker.popup = start
finish_marker.popup = finish

zoom_slider = IntSlider(description='Масштаб:', min=11, max=15, value=14)
jslink((zoom_slider, 'value'), (m, 'zoom'))
widget_control1 = WidgetControl(widget=zoom_slider, position='topright')
m.add_control(widget_control1)

# m

m.save('marathon_map.html')  # Сохраняем карту в HTML файл

"""#### Карта 85 субъектов РФ"""

import os
import json
import random
import requests
from ipyleaflet import GeoJSON

def load_data(url, filename, file_type):
    r = requests.get(url)
    with open(filename, 'w') as f:
        f.write(r.content.decode("utf-8"))
    with open(filename, 'r') as f:
        return file_type(f)

data = load_data(
    'https://raw.githubusercontent.com/tttdddnet/Python-Jupyter-Geo/main/geo_ru.json',
    'geo_ru.json',
     json.load)

def random_color(feature):
    return {
        'color': 'black',
        'fillColor': random.choice(['red', 'yellow', '#efed69', '#fcba03', '#9900ff', '#00ff15', '#db2751', '#00ff95']),
    }

m = Map(center=(66.25, 94.15), zoom=3)

geo_json = GeoJSON(
    data=data,
    style={
        'opacity': 1, 'dashArray': '9', 'fillOpacity': 0.2, 'weight': 1
    },
    hover_style={
        'color': 'white', 'dashArray': '0', 'fillOpacity': 0.7
    },
    style_callback=random_color
)

m.add_layer(geo_json)

m.save('russia_map.html')  # Сохраняем карту в HTML файл

"""## ~~ДЗ №4~~ задания по геоданным не будет. Перейти по ссылке, которое дано в начале и попробовать самостоятельно разобраться

1. ~~Выбрать любой казанский автобусный маршрут;~~
2. ~~проследить с помощью API сайта data.kzn.ru за автобусом выбранного маршрута достаточное количество времени, чтобы сформировать представление о всём пути следования автобуса;~~
3. ~~изобразить маршрут на карте;~~
4. ~~подумайте, как найти правильный центр рисунка;~~
5. ~~подумайте как найти и указать на рисунке остановки выбранного маршрута.~~

## 4. Тексты

### Сбор данных через VK API

1. Авторизуйтесь ВКонтакте и зайдите на страничку разработчиков **https://dev.vk.com/**

2. Нажимите на кнопку **"Создать приложение"**.

3. Введите имя, тип Standalone, нажите **"Подключить приложение"**.

4. Подтвердите действие.

5. После создания приложения зайдите в его настройки и скопируйте его идентификатор. Нажмите на кнопку **"Редактировать"** рядом с нужным приложением. В адресной строке появится его id. \
Из этой ссылки: https://vk.com/editapp?id=8031498 видно, что id=8031498.

6. Соберите ссылку для получения ключа.\
Плюсом токена для параноиков является то, что он может быть выдан на определённый срок.\
Полезная информация по настройкам:
https://dev.vk.com/api/access-token/implicit-flow-user \\
Токен можно получить прямо из браузера. Для этого нужно только перейти по правильной ссылке. Как составить правильную ссылку:\
https://oauth.vk.com/authorize?client_id=8031498&display=page&redirect_uri=https://oauth.vk.com/blank.html&response_type=token&v=5.103&state=123456

7. Перейдите по собранной ссылке.\
Вы получите access_token — строку наподобие:  **f367ca560512280f3668289211770e74afadd78ca79c5198a6f64875b63b060de43a339a3b4110e49b902** \
Она появится в адресной строке, подписанная как access_token.\
https://oauth.vk.com/blank.html#access_token=f367ca560512280f3668289211770e74afadd78ca79c5198a6f64875b63b060de43a339a3b4110e49b902&expires_in=86400&user_id=8031498&state=123456
"""

token = ''
# Получение токена выдает ошибку :(

# https://vk.com/mashinnoe_obuchenie_ai_big_data
ID = 'mashinnoe_obuchenie_ai_big_data'

import requests
from datetime import datetime

num_item = 0
json_response = requests.get(('https://api.vk.com/method/wall.get?count=10&offset={}&domain={}&v=5.103&access_token=' + token).\
                        format(0, ID)).json()

if json_response.get('error'):
    print(json_response.get('error'))
else:
    for item in json_response['response']['items']:
        print(num_item, ": ", datetime.fromtimestamp(item['date']))
        print(item['text'])
        print('--------------')
        num_item += 1

"""## ДЗ № 5

1. Создайте приложения для работы с API VK;
2. получите свой токен для автоматизации действий в соцсети;
3. соберите не менее 2000 не пустых текстовых сообщений со стены любой открытой группы;
4. сохраните сообщения во внешний файл для дальнейшего чтения и работы.
"""

